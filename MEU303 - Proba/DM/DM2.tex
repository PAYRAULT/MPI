\documentclass[]{book}

%These tell TeX which packages to use.
\usepackage{array,epsfig}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsxtra}
\usepackage{amsthm}
\usepackage{mathrsfs}
\usepackage{color}
\usepackage[margin=2cm,top=2.5cm,headheight=16pt,headsep=0.1in,heightrounded]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
%\usepackage{tikz}
\usepackage{pgfplots}

%Here I define some theorem styles and shortcut commands for symbols I use often
\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}
\newtheorem*{rmk}{Remark}
\newtheorem{lem}{Lemma}
\newtheorem*{joke}{Joke}
\newtheorem{ex}{Example}
\newtheorem*{soln}{Solution}
\newtheorem{prop}{Proposition}

\newcommand{\lra}{\longrightarrow}
\newcommand{\ra}{\rightarrow}
\newcommand{\surj}{\twoheadrightarrow}
\newcommand{\graph}{\mathrm{graph}}
\newcommand{\bb}[1]{\mathbb{#1}}
\newcommand{\Z}{\bb{Z}}
\newcommand{\Q}{\bb{Q}}
\newcommand{\R}{\bb{R}}
\newcommand{\E}{\bb{E}}
\newcommand{\C}{\bb{C}}
\newcommand{\N}{\bb{N}}
\newcommand{\M}{\mathbf{M}}
\newcommand{\m}{\mathbf{m}}
\newcommand{\MM}{\mathscr{M}}
\newcommand{\HH}{\mathscr{H}}
\newcommand{\Om}{\Omega}
\newcommand{\Ho}{\in\HH(\Om)}
\newcommand{\bd}{\partial}
\newcommand{\del}{\partial}
\newcommand{\bardel}{\overline\partial}
\newcommand{\textdf}[1]{\textbf{\textsf{#1}}\index{#1}}
\newcommand{\img}{\mathrm{img}}
\newcommand{\ip}[2]{\left\langle{#1},{#2}\right\rangle}
\newcommand{\inter}[1]{\mathrm{int}{#1}}
\newcommand{\exter}[1]{\mathrm{ext}{#1}}
\newcommand{\cl}[1]{\mathrm{cl}{#1}}
\newcommand{\ds}{\displaystyle}
\newcommand{\vol}{\mathrm{vol}}
\newcommand{\cnt}{\mathrm{ct}}
\newcommand{\osc}{\mathrm{osc}}
\newcommand{\LL}{\mathbf{L}}
\newcommand{\UU}{\mathbf{U}}
\newcommand{\support}{\mathrm{support}}
\newcommand{\AND}{\;\wedge\;}
\newcommand{\OR}{\;\vee\;} 
\newcommand{\Oset}{\varnothing}
\newcommand{\st}{\ni}
\newcommand{\wh}{\widehat}
\newcommand{\vect}[1]{\overrightarrow{#1}}

%Pagination stuff.
%\setlength{\oddsidemargin}{0in}
%\setlength{\evensidemargin}{0in}
\setlength{\textheight}{9.in}
\setlength{\textwidth}{6.5in}
\cfoot{page \thepage}
\lhead{MEU302 - Alg\`ebre}
\rhead{TD2}
\pagestyle{fancy}


\begin{document}

\subsection*{Exercice 5}
\subsection*{Question 5.A.1}

$$
\int_{-\infty}^{+\infty}{\frac{m \theta^m}{x^{m+1}}1_{\lceil \theta, \infty[}(x) dx} = 
\int_{-\infty}^{\theta}{\frac{m \theta^m}{x^{m+1}}1_{\lceil \theta, \infty[}(x) dx} + \int_{\theta}^{+\infty}{\frac{m \theta^m}{x^{m+1}}1_{\lceil \theta, \infty[}(x) dx}
$$
$$
0 + \int_{\theta}^{+\infty}{\frac{m \theta^m}{x^{m+1}} dx} =
\left[\frac{\theta^m}{x^m}\right]_{\theta}^{+\infty} =
\frac{\theta^m}{\theta^m} - \frac{\theta^m}{\infty^m} = 1 - 0 = 1
$$

\subsection*{Question 5.A.2}
$$
\forall t \geq \theta, P(X \geq t) = \forall t \geq \theta, 1 - P(X < t) = 1- \int_{\theta}^{t}{\frac{m \theta^m}{x^{m+1}} dx} = 1 - \left[\frac{\theta^m}{x^m}\right]_{\theta}^{t} = \left( \frac{\theta}{t}\right)^m
$$


\subsection*{Question 5.A.3}
$$
E(X) = \int_{-\infty}^{+\infty}{x \frac{m \theta^m}{x^{m+1}}1_{\lceil \theta, \infty[}(x) dx} =
0 + \int_{\theta}^{+\infty}{x\frac{m \theta^m}{x^{m+1}} dx} =
m \theta^m \int_{\theta}^{+\infty}{\frac{1}{x^{m}} dx} = 
$$
$$
m \theta^m \left[-\frac{1}{(m-1)x^{m-1}}\right]_{\theta}^{+\infty} = 
-\frac{m \theta^m}{m-1} \left(0 - \frac{1}{\theta^{m-1}}\right) =
\frac{m \theta}{m-1}
$$

\bigskip

$$
E(X^2) = \int_{-\infty}^{+\infty}{x^2 \frac{m \theta^m}{x^{m+1}}1_{\lceil \theta, \infty[}(x) dx} =
0 + \int_{\theta}^{+\infty}{x^2\frac{m \theta^m}{x^{m+1}} dx} =
m \theta^m \int_{\theta}^{+\infty}{\frac{1}{x^{m-1}} dx} = 
$$
$$
m \theta^m \left[-\frac{1}{(m-2)x^{m-2}}\right]_{\theta}^{+\infty} = 
-\frac{m \theta^m}{m-2} \left(0 - \frac{1}{\theta^{m-2}}\right) =
\frac{m \theta^2}{m-2}
$$

\subsection*{Question 5.A.3}

$$
V(X) = E(X^2) - E(X)^2 = \frac{m \theta^2}{m-2} - \left( \frac{m \theta}{m-1} \right)^2 =
$$
$$
\frac{m(m-1)^2-m^2(m-2)}{(m-2)(m-1)^2}\theta^2 = 
\frac{m}{(m-2)(m-1)^2}\theta^2
$$


\subsection*{Question 5.B.1}

M\'ethode des moments de niveau 1, $M_1 = \frac{1}{n}\sum_{i=1}^{n}{X_i}$, et $E(X) = M_1$ donc 
$$
M_1 = \frac{m \theta}{m-1}
$$
Donc l'estimateur est
$$
\hat{\theta_1} = \frac{m-1}{m}M_1 = \frac{m-1}{m}\frac{1}{n}\sum_{i=1}^{n}{X_i}
$$
Comme $m=3$, on a
$$
\hat{\theta_1} = \frac{2}{3}\frac{1}{n}\sum_{i=1}^{n}{X_i}
$$


TBC

\subsection*{Question 5.B.2.a}
M\'ethode du maximum de vraissemblance, on a 
$$
L_{\theta}(X) = \prod_{i=1}^{n}{\frac{3\theta^3}{x_i^{4}}1_{[\theta, \infty[}(x_i)} = 3^{n}\theta^{3n}\prod_{i=1}^{n}{\frac{1}{x_i^4}1_{[\theta, \infty[}(x_i)}
$$

On traite 2 cas :
\begin{itemize}
\item Lorsque $\theta > \min\{x_i\}$, la fonction $1_{[\theta, \infty[}(x) = 0$ pour $x = \min\{x_i\}$. Donc, on a $L_{\theta}(X) = 0$.   
\item Lorsque $\theta \leq \min\{x_i\}$, la fonction $1_{[\theta, \infty[}(x) = 1, \forall x \in \{x_i\}$. Donc, on a $L_{\theta}(X) > 0$.
\end{itemize}
La fonction de vraissemblance de $L_{\theta}(X) = C \theta^3n$ o\`u $C$ est un terme constant dependant de $X$. Par cons\'equent, Le maximum de vraissemblance correspond \`a la plus grande valeur possible de $\theta$. Donc $\hat{\theta_2} = \min\{x_i\}$.


\subsection*{Question 5.B.2.b}
La fonction de r\'epartition de $\hat{\theta_2}$ est $F(t) = P(\min_{1 \leq i \leq n} X_i <t)$. Donc
$$
P(\min_{1 \leq i \leq n} X_i <t) = 1 - P(\min_{1 \leq i \leq n} X_i \geq t) = 1 - P(x_1 \geq t, \ldots, x_n \geq t) =
1 - \prod_{i=1}^{n}{P(x_i \geq t)} = 1 - \prod_{i=1}^{n}{\left(\frac{\theta}{t}\right)^31_{[\theta, \infty[}(t)}
$$
$$
= 1 - \left(\frac{\theta}{t}\right)^{3n}1_{[\theta, \infty[}(t) = P(3n, \theta)
$$

\subsection*{Question 5.B.2.c}
La fonction de r\'epartition de $\hat{\theta_2}$ suit une loit de Pareto $P(3n, \theta)$, l'esp\'erance et la variance de la loi de Pareto $P(m, \theta)$ sont resp. $\frac{m\theta}{m-1}$ et $\frac{m}{(m-2)(m-1)^2}\theta^2$ (voir questions pr\'eliminaires), donc
$$
E[\hat{\theta_2}] = \frac{3n}{3n-1}\theta
$$ 
et 
$$
V[\hat{\theta_2}] = \frac{3n}{(3n-2)(3n-1)^2}\theta^2
$$

\subsection*{Question 5.B.3}
Prenons $\hat{\theta_3} = \frac{\hat{\theta_2}+\hat{\theta_1}}{2}$ on a 
$$
E(\hat{\theta_3}) = E\left(\frac{\hat{\theta_2}+\hat{\theta_1}}{2}\right) = \frac{E(\hat{\theta_2})+E(\hat{\theta_1})}{2} = \frac{\theta + \theta}{2} = \theta
$$

Donc l'estimateur $\hat{\theta_3}$ est sans biais.

et

$$
R(\hat{\theta_3}, \theta) = V(\hat{\theta_3}) + B(\hat{\theta_3}, \theta)^2 = V(\hat{\theta_3})
= E(\hat{\theta_3}^2) - E(\hat{\theta_3})^2 = 
$$
$$
E\left(\left(\frac{\hat{\theta_1}+\hat{\theta_2}}{2}\right)^2\right) - \left(\frac{E(\hat{\theta_1})+E(\hat{\theta_2}) }{2}\right)^2 = \frac{1}{4}(E(\hat{\theta_1}^2) + 2E(\hat{\theta_1}\hat{\theta_2}) + E(\hat{\theta_2}^2) - E(\hat{\theta_1})^2 - 2E(\hat{\theta_1})E(\hat{\theta_2}) - E(\hat{\theta_2})^2)
$$
$$
= \frac{1}{4}(V(\hat{\theta_1}) + V(\hat{\theta_2}) + 2E(\hat{\theta_1}\hat{\theta_2}) - 2E(\hat{\theta_1})E(\hat{\theta_2}))
$$





\end{document}

